<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Notes from GTC'25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency - Part 2 | Shreyansh Singh </title> <meta name="author" content="Shreyansh Singh"> <meta name="description" content="Second part of my notes from the talk on maximizing memory bandwidth at NVIDIA GTC 2025."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link defer href="/assets/css/toc-custom.css?018b6fb1db2a03192ea04ff844223cb2" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile_pictures/favicon.ico?7def459033b808c2a47593bed4cfb002"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shreyansh26.github.io/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shreyansh</span> Singh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/post/index.html">Posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/bookshelf/">Bookshelf </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resume/Resume_Shreyansh.pdf">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Notes from GTC'25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency - Part 2</h1> <p class="post-meta"> Published on March 23, 2025 by Shreyansh Singh </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/cuda"> <i class="fa-solid fa-hashtag fa-sm"></i> cuda</a>   <a href="/blog/tag/mlsys"> <i class="fa-solid fa-hashtag fa-sm"></i> mlsys</a>   ·   <a href="/blog/category/mlsys"> <i class="fa-solid fa-tag fa-sm"></i> MLSys</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <hr> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/cover.png" alt=""> <figcaption></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>You can watch the talk here - <a href="https://register.nvidia.com/flow/nvidia/gtcs25/vap/page/vsessioncatalog/session/1727709012449001X6PZ" rel="external nofollow noopener" target="_blank">link</a></p> <p>Part 1 of the talk focused on maximizing memory throughput. The notes can be found <a href="/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-1/">here</a>.</p> <p>These are the notes for the second part of the talk which focused on memory models and hiding latency.</p> <hr> <h1 id="memory-model">Memory Model</h1> <hr> <p>Memory model is a way to understand how memory is accessed and used in a program. It is a contract between the user and the compiler/hardware/language.</p> <h2 id="single-threaded">Single-threaded</h2> <p>Standard memory model. <br> Stores are visible to the thread that stored them. <br> Loads and stores to the same address remain in order - they cannot overtake each other in the memory subsystem.</p> <p>Important concept - <strong>same-address ordering</strong>. <br> Same-address ordering does not hold always. E.g. when using constant caches. The constant caches have a link to the L2 cache but not to the L1 cache. Hence, these caches are not coherent.</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/constant_cache.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>So, constant cached values can cause issues. You can do the store - which would go through L1 to the L2 and update it. However, during load, the constant cache is used and it returns the old value.</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/constant_cache_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <h2 id="memory-ordering">Memory Ordering</h2> <p>Memory order specifies how memory accesses, including regular (non-atomic) accesses, are to be ordered around an atomic operation.</p> <p>Four important memory orders in multi-threaded memory model:</p> <ol> <li>Sequentially consistent</li> <li>Acquire</li> <li>Release</li> <li>Relaxed</li> </ol> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/memory_ordering.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <h2 id="multi-threaded">Multi-threaded</h2> <h3 id="cuda-c-scope">CUDA C++ Scope</h3> <ul> <li>Thread - <code class="language-plaintext highlighter-rouge">cuda::thread_scope_thread</code> - Only local thread can observe this thread’s loads and stores</li> <li>Thread Block - <code class="language-plaintext highlighter-rouge">cuda::thread_scope_block</code> - Only threads in the same block can observe this thread’s loads and stores</li> <li>GPU Device - <code class="language-plaintext highlighter-rouge">cuda::thread_scope_device</code> - All threads in the GPU can observe this thread’s loads and stores</li> <li>System - <code class="language-plaintext highlighter-rouge">cuda::thread_scope_system</code> - All threads in the system (CPU, other GPUs, other nodes) can observe this thread’s loads and stores</li> </ul> <h3 id="cuda-ptx-scope">CUDA PTX Scope</h3> <ul> <li>Thread Block - <code class="language-plaintext highlighter-rouge">.cta</code> - Only threads in the same block can observe this thread’s loads and stores</li> <li>GPU Device - <code class="language-plaintext highlighter-rouge">.gpu</code> - All threads in the GPU can observe this thread’s loads and stores</li> <li>System - <code class="language-plaintext highlighter-rouge">.sys</code> - All threads in the system (CPU, other GPUs, other nodes) can observe this thread’s loads and stores</li> </ul> <h3 id="thread-scope---block">Thread scope - Block</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/ts_block.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Threads in the same block execute on same SM. <br> Data only has to be consistent in L1. All threads in the block see the same data. <br> Release and acquire semantics are quite fast. Because data does not have to be flushed very far. We don’t have to invalidate many caches.</p> <h3 id="thread-scope---cluster">Thread scope - Cluster</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/ts_cluster.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Many threads working across multiple SMs working together. <br> Data has to go through L2. <br> <strong>In release, we would have to flush to L2 and in acquire, we would have to make sure that L1 is invalidated.</strong></p> <h3 id="thread-scope---gpu">Thread scope - GPU</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/ts_system.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Many threads working across multiple SMs of a GPU working together. <br> Synchronization is as difficult as cluster. <br> <strong>In release, we would have to flush to L2 and in acquire, we would have to make sure that L1 is invalidated.</strong></p> <h3 id="thread-scope---system">Thread scope - System</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/ts_system.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Many threads working across multiple GPUs working together. <br> <strong>In release, we would have to make sure that all the stores made it to the relevant caches across GPUs and nodes.</strong> <br> <strong>Acquire is still cheap, all L1s need to be invalidated.</strong></p> <h3 id="data-transfer-examples">Data transfer examples</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/relaxed_1.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/relaxed_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Using thread scope <code class="language-plaintext highlighter-rouge">block</code> when working with same block.</p> <p>Using thread scope <code class="language-plaintext highlighter-rouge">device</code> when working with different thread blocks.</p> <p>But, for a not so relaxed example, where there are two variables we need to work with, simply using <code class="language-plaintext highlighter-rouge">device</code> scope is not enough.</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/not_relaxed_3.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p><strong>We need to use a release-acquire pattern.</strong></p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/not_relaxed_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <h3 id="relaxed-vs-release-acquire">Relaxed vs Release-Acquire</h3> <p><strong>Relaxed</strong></p> <ul> <li>Faster - A single store or load to or from the cache at the point of coherency.</li> <li>Does not provide ordering w.r.t other reads and writes.</li> <li>Useful if two threads want to exchange one value.</li> </ul> <p><strong>Release-Acquire</strong></p> <ul> <li>Slower - Requires flushing to point of coherency and / or invalidating caches.</li> <li>Provides ordering w.r.t other reads and writes.</li> <li>Useful if multiple threads want to exchange multiple values.</li> </ul> <p>For larger chunks of data, release-acquire is preferred.</p> <h2 id="async-thread---ampere">Async thread - Ampere</h2> <p><strong>PTX instruction <code class="language-plaintext highlighter-rouge">st.async</code></strong></p> <ul> <li>Stores a value to Distributed Shared Memory of another block in the cluster/</li> <li>Once the store is complete, it updates a shared memory barrier in the shared memory of the other block.</li> </ul> <p><strong>However, a subsequent load or store can race ahead, violating the same-address ordering.</strong></p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/store_async.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <h2 id="async-proxy---hopper">Async proxy - Hopper</h2> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_proxy.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Proxies represent situations where there are multiple different paths from a single thread to a single physical memory location, with no coherence across paths.</p> <p><strong>Generic Proxy</strong> - All normal loads and stores go through the generic proxy. <br> <strong>Async Proxy</strong> - A different path that is used by TMA units, tensor cores and several other instructions.</p> <p>Between a generic proxy load/store and an async proxy load/store, there is <strong>no same-address ordering</strong>. Even less than earlier (async threads).</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_proxy_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>The normal store can overtake the TMA load.</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_proxy_code_1.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Here, the generic proxy store to shared memory will be most likely overtaken by async proxy load from shared memory. <br> This will store stale values to global memory.</p> <h3 id="async-proxy-fence">Async Proxy Fence</h3> <p><strong>Solution is to use an async proxy fence</strong> -</p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_proxy_2_fence.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>The fence traces the store to shared memory, and makes sure that the store is complete. Once it is complete, the fence comes back, notifies the thread and only then will the TMA load be allowed to proceed.</p> <p><strong>Implicit Fencing</strong></p> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_implicit_fence.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Here we start waiting on the barrier after the copy async bulk is issued. Barrier waiting request goes to to the shared memory until the load is finished. Only when all the required updates to the shared memory are done (stores), the barrier is updated.</p> <h2 id="async-thread-and-async-proxy-instructions">Async thread and Async proxy instructions</h2> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/async_thread_proxy_instructions.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li> <code class="language-plaintext highlighter-rouge">st.async</code> and <code class="language-plaintext highlighter-rouge">red.async</code> are in Hopper but still async thread only</li> <li> <code class="language-plaintext highlighter-rouge">cp.async</code> - Ampere</li> <li>If you have a normal load and store before - obeys same-address ordering</li> <li>But normal load and store after - it will not obey</li> <li>Async proxy fence is still needed to ensure correct ordering</li> </ul> <h1 id="low-latency-cluster-synchronization">Low-Latency Cluster Synchronization</h1> <hr> <p><strong>Key points</strong></p> <ul> <li>The point of coherency for a cluster is L2 - thread blocks can be in different SMs</li> <li>Any release-acquire pattern with cluster scope requires a round trip to L2 which is expensive</li> <li>To reduce latency - avoid these round trips</li> </ul> <h2 id="thread-synchronization-in-a-cluster">Thread synchronization in a cluster</h2> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/low_latency_1.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Arrive has to be executed by all threads in a cluster but wait doesn’t need to be. <br> The arrive can have different memory model orderings.</p> <ul> <li>Release - Requires flushing to L2 but gives synchronization of data</li> <li>Relaxed - Only execution synchronization but no data synchronization</li> </ul> <h3 id="barrier-initialization---simple-way">Barrier Initialization - Simple way</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/low_latency_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Initializing a shared memory barrier and making it visible to all threads in the cluster. <br> A cluster sync is done to make the barrier visible to all threads. <br> Nothing needs to be flushed to L2 =&gt; this is more expensive than it has to be.</p> <h3 id="barrier-initialization---fast-way">Barrier Initialization - Fast way</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/low_latency_3.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>Instead of <code class="language-plaintext highlighter-rouge">cluster::sync</code>, we use a <strong>relaxed arrive</strong> which does not flush anything to L2, but ensures execution synchronization. <br> But to ensure correctness, we do a release fence of just the mbarrier init. <br> Additionally there is a release-acquire pattern and they have to be scope clusters. <br> <code class="language-plaintext highlighter-rouge">fence_mbarrier_init</code>, <code class="language-plaintext highlighter-rouge">arrive</code> and <code class="language-plaintext highlighter-rouge">wait</code> are all fairly cheap.</p> <p>For kernels which are short, this type of optimization can help a lot. However, for long kernels, this won’t help much.</p> <h2 id="data-communication-in-a-cluster">Data communication in a cluster</h2> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/data_comm_1.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/data_comm_2.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>Arrival should be relaxed and scope_cluster. If it were a release, then it would have a flush to L2.</li> <li>Wait from other cluster should be acquire (in a loop) so that it can form a release-acquire pattern with <code class="language-plaintext highlighter-rouge">st_async</code>. As <code class="language-plaintext highlighter-rouge">st_async</code> just releases the 4 bytes it has stored and that’s what we acquire in the <code class="language-plaintext highlighter-rouge">mbarrier_try_wait</code> which is also a scope cluster and you wait on the local barrier which is cheap.</li> <li>FInally, we need to make sure the other thread in the cluster got our value before we send another. This can be relaxed as we just need to ensure execution synchronization.</li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/gtc_memory_bandwidth/data_comm_3.png" alt="Source: Slides from the talk"> <figcaption>Source: Slides from the talk</figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{display:block;width:100%;height:auto;max-width:100%}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>But again, this helps only for short kernels. For long kernels, this won’t help much. We can fo go for the simple code.</p> <hr> <p>Hope this was helpful!</p> <p>Notes for part 1 on maximizing memory bandwidth can be found <a href="/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-1/">here</a>.</p> <hr> <p> </p> <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script> <div class="button_cont" align="center"><button id="openpopup" class="example_a">Subscribe to my posts!</button></div> <style>.example_a{color:#fff!important;text-transform:uppercase;text-decoration:none;background:#3f51b5;padding:20px;border-radius:5px;cursor:pointer;display:inline-block;border:0;transition:all .4s ease 0}.example_a:hover{background:#434343;letter-spacing:1px;-webkit-box-shadow:0 5px 40px -10px rgba(0,0,0,0.57);-moz-box-shadow:0 5px 40px -10px rgba(0,0,0,0.57);box-shadow:5px 40px -10px rgba(0,0,0,0.57);transition:all .4s ease 0}</style> <script type="text/javascript">function showMailingPopUp(){window.dojoRequire(["mojo/signup-forms/Loader"],function(o){o.start({baseUrl:"mc.us4.list-manage.com",uuid:"0b10ac14f50d7f4e7d11cf26a",lid:"667a1bb3da",uniqueMethods:!0})}),document.cookie="MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC"}document.getElementById("openpopup").onclick=function(){showMailingPopUp()};</script> <p> </p> <script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js" data-id="shreyanshsingh" data-description="Support me on Buy me a coffee!" data-message="" data-color="#FF5F5F" data-position="Right" data-x_margin="18" data-y_margin="18"></script> <p>Follow me on <a href="https://twitter.com/shreyansh_26" rel="external nofollow noopener" target="_blank">Twitter</a>, <a href="https://github.com/shreyansh26" rel="external nofollow noopener" target="_blank">Github</a> or connect on <a href="https://www.linkedin.com/in/shreyansh26/" rel="external nofollow noopener" target="_blank">LinkedIn</a>.</p> </div> </article> <div id="giscus_thread" style="max-width: 1200px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"shreyansh26/shreyansh26.github.io","data-repo-id":"R_kgDOMn767Q","data-category":"General","data-category-id":"DIC_kwDOMn767c4CiLUv","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Shreyansh Singh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?317646887210841a1b23a5eedc9fba39"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZEZ7673Y7G"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-ZEZ7673Y7G");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-posts",title:"Posts",description:"",section:"Navigation",handler:()=>{window.location.href="/post/index.html"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-bookshelf",title:"Bookshelf",description:"A list of books I&#39;ve read and some of which I&#39;ve found interesting :)",section:"Navigation",handler:()=>{window.location.href="/bookshelf/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/resume/Resume_Shreyansh.pdf"}},{id:"post-notes-from-gtc-39-25-cuda-techniques-to-maximize-compute-and-instruction-throughput",title:"Notes from GTC&#39;25: CUDA Techniques to Maximize Compute and Instruction Throughput",description:"My notes from the talk on maximizing compute and instruction throughput at NVIDIA GTC 2025.",section:"Posts",handler:()=>{window.location.href="/post/2025-04-04_gtc25-maximize-compute-instruction-throughput/"}},{id:"post-notes-from-gtc-39-25-cuda-techniques-to-maximize-memory-bandwidth-and-hide-latency-part-2",title:"Notes from GTC&#39;25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency -...",description:"Second part of my notes from the talk on maximizing memory bandwidth at NVIDIA GTC 2025.",section:"Posts",handler:()=>{window.location.href="/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-2/"}},{id:"post-notes-from-gtc-39-25-cuda-techniques-to-maximize-memory-bandwidth-and-hide-latency-part-1",title:"Notes from GTC&#39;25: CUDA Techniques to Maximize Memory Bandwidth and Hide Latency -...",description:"First part of my notes from the talk on maximizing memory bandwidth at NVIDIA GTC 2025.",section:"Posts",handler:()=>{window.location.href="/post/2025-03-23_gtc25-maximize-memory-bandwidth-part-1/"}},{id:"post-faster-cross-encoder-inference-unleashing-torch-compile-for-speed",title:"Faster Cross-Encoder Inference: Unleashing torch.compile for speed",description:"A quick writeup on accelerating a Jina Cross-Encoder using torch.compile",section:"Posts",handler:()=>{window.location.href="/post/2025-03-02_cross-encoder-inference-torch-compile/"}},{id:"post-paper-summary-13-physics-of-language-models-part-2-1-grade-school-math-and-the-hidden-reasoning-process",title:"Paper Summary #13 - Physics of Language Models: Part 2.1, Grade-School Math and...",description:"My notes from the Physics of Language Models series of papers.",section:"Posts",handler:()=>{window.location.href="/post/2024-09-21_physics-of-lms-2-1-grade-school-math-and-the-hidden-reasoning-process/"}},{id:"post-paper-summary-12-image-recaptioning-in-dall-e-3",title:"Paper Summary #12 - Image Recaptioning in DALL-E 3",description:"The image recaptioning technique used in DALL-E 3 was extended to videos in Sora.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_dalle3_image_recaptioner/"}},{id:"post-paper-summary-11-sora",title:"Paper Summary #11 - Sora",description:"OpenAI announced a ground-breaking text-to-video diffusion model capable of generating high-definition videos up to 60 seconds long.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_sora_openai/"}},{id:"post-paper-summary-10-gemini-1-5-pro",title:"Paper Summary #10 - Gemini 1.5 Pro",description:"Google DeepMind announced a multimodal LLM with support of up to 10M context length.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_gemini_pro_google/"}},{id:"post-solving-substitution-ciphers-using-markov-chain-monte-carlo-mcmc",title:"Solving Substitution Ciphers using Markov Chain Monte Carlo (MCMC)",description:"Deciphering substitution ciphers can be framed as a Markov chain problem and a simple Monte Carlo sampling approach can help solve them very efficiently",section:"Posts",handler:()=>{window.location.href="/post/2023-07-22_solving_substitution_cipher_using_mcmc/"}},{id:"post-paper-summary-9-sophia-a-scalable-stochastic-second-order-optimizer-for-language-model-pre-training",title:"Paper Summary #9 - Sophia: A Scalable Stochastic Second-order Optimizer for Language Model...",description:"Understanding Sophia - A new fast, scalable second-order optimizer which beats Adam on LLM pretraining.",section:"Posts",handler:()=>{window.location.href="/post/2023-05-28_sophia_scalable_second_order_optimizer_llms/"}},{id:"post-paper-summary-8-flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness",title:"Paper Summary #8 - FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",description:"Understanding FlashAttention which is the most efficient exact attention implementation out there, which optimizes for both memory requirements and wall-clock time.",section:"Posts",handler:()=>{window.location.href="/post/2023-03-26_flash-attention/"}},{id:"post-paper-summary-7-efficient-transformers-a-survey",title:"Paper Summary #7 - Efficient Transformers: A Survey",description:"A survey paper of improvements over the original Transformer architecture in terms of memory-efficiency.",section:"Posts",handler:()=>{window.location.href="/post/2022-10-10_efficient_transformers_survey/"}},{id:"post-deploying-machine-learning-models-using-gcp-39-s-google-ai-platform-a-detailed-tutorial",title:"Deploying Machine Learning models using GCP&#39;s Google AI Platform - A Detailed Tutorial...",description:"A step-wise tutorial to demonstrate the steps required to deploy a ML model using GCP, specifically the Google AI Platform and use Streamlit to access the model through a UI.",section:"Posts",handler:()=>{window.location.href="/post/2022-03-06_model_deployment_using_gcp_google_ai_platform/"}},{id:"post-deploying-machine-learning-models-using-aws-lambda-and-github-actions-a-detailed-tutorial",title:"Deploying Machine Learning models using AWS Lambda and Github Actions - A Detailed...",description:"A step-wise tutorial to demonstrate the steps required to deploy a ML model using AWS Lambda, Github Actions, API Gateway and use Streamlit to access the model API through a UI.",section:"Posts",handler:()=>{window.location.href="/post/2022-01-23_model_deployment_using_aws_lambda/"}},{id:"post-ppml-series-3-federated-learning-for-mobile-keyboard-prediction",title:"PPML Series #3 - Federated Learning for Mobile Keyboard Prediction",description:"Understanding how your mobile keyboard (Gboard, specifically) performs the next word prediction task and performs model training and updates",section:"Posts",handler:()=>{window.location.href="/post/2021-12-27_federated_learning_mobile_keyboard/"}},{id:"post-ppml-series-2-federated-optimization-algorithms-fedsgd-and-fedavg",title:"PPML Series #2 - Federated Optimization Algorithms - FedSGD and FedAvg",description:"A mathematical deep dive on a Federated Optimization algorithm - FedAvg and comparing it with a standard approach - FedSGD.",section:"Posts",handler:()=>{window.location.href="/post/2021-12-18_federated_optimization_fedavg/"}},{id:"post-ppml-series-1-an-introduction-to-federated-learning",title:"PPML Series #1 - An introduction to Federated Learning",description:"A short general introduction to Federated Learning (FL) for folks interested in privacy-preserving machine learning (PPML).",section:"Posts",handler:()=>{window.location.href="/post/2021-12-11_intro_to_federated_learning/"}},{id:"post-paper-summary-6-language-models-are-unsupervised-multitask-learners",title:"Paper Summary #6 - Language Models are Unsupervised Multitask Learners",description:"The GPT2 model which aimed to perform complex NLP tasks while relying only on a language model trained in a completely unsupervised fashion.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/"}},{id:"post-paper-summary-5-xlnet-generalized-autoregressive-pretraining-for-language-understanding",title:"Paper Summary #5 - XLNet: Generalized Autoregressive Pretraining for Language Understanding",description:"XLNet tries to overcome the limitations of BERT by having a autoregressive component while also capturing the bidirectional context.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/"}},{id:"post-paper-summary-4-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding",title:"Paper Summary #4 - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding...",description:"The ground breaking paper that introduced the famous BERT model. This started the inflow of a large number of BERT-based language understanding models.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/"}},{id:"post-paper-summary-3-improving-language-understanding-by-generative-pre-training",title:"Paper Summary #3 - Improving Language Understanding by Generative Pre-Training",description:"The first paper in the GPT set of models. This is OpenAI&#39;s GPT-1.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-02_language_understanding_generative_pretraining/"}},{id:"post-paper-summary-2-deep-contextualized-word-representations-elmo",title:"Paper Summary #2 - Deep contextualized word representations (ELMo)",description:"The second post in the paper notes series. This time we take a look at ELMo.",section:"Posts",handler:()=>{window.location.href="/post/2021-04-25_deep_contextualized_word_representations_elmo/"}},{id:"post-paper-summary-1-attention-is-all-you-need",title:"Paper Summary #1 - Attention Is All You Need",description:"The first of the paper summary series. This is where I briefly summarise the important papers that I read for my job or just for fun :P",section:"Posts",handler:()=>{window.location.href="/post/2021-04-18_attention_is_all_you_need/"}},{id:"post-deep-learning-in-the-browser-exploring-tf-js-webdnn-and-onnx-js",title:"Deep Learning in the Browser - Exploring TF.js, WebDNN and ONNX.js",description:"A quick tutorial to set up a small scale deployment for your ML or DL model",section:"Posts",handler:()=>{window.location.href="/post/2021-01-25_deep_learning_in_the_browser/"}},{id:"post-quick-tutorial-to-deploy-your-ml-models-using-fastapi-and-docker",title:"Quick tutorial to deploy your ML models using FastAPI and Docker",description:"Just a quick tutorial to set up a small scale deployment for your ML or DL model",section:"Posts",handler:()=>{window.location.href="/post/2020-11-30_fast_api_docker_ml_deploy/"}},{id:"post-androids-encryption-crypto-pwn2win-ctf-2020",title:"Androids Encryption (Crypto) - Pwn2Win CTF 2020",description:"My writeup for Androids Encryption challenge in the Pwn2Win CTF 2020",section:"Posts",handler:()=>{window.location.href="/post/2020-06-01_androids_encryption-pwn2win-2020/"}},{id:"post-malwaretech-39-s-vm1-reversing-challenge",title:"MalwareTech&#39;s VM1 Reversing Challenge",description:"My writeup for the VM1 reversing challenge posted by MalwareTech on his website.",section:"Posts",handler:()=>{window.location.href="/post/2020-01-04_malwaretech-vm1-challenge/"}},{id:"post-hxp-36c3-ctf-writeups",title:"hxp 36C3 CTF Writeups",description:"The writeups for the challenges I solved in the first MAJOR CTF that I participated in after a long time.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-30_hxp-36c3-ctf/"}},{id:"post-watevrctf-2019-writeups-mainly-rev-and-pwn",title:"watevrCTF 2019 Writeups (Mainly Rev and Pwn)",description:"My writeups for the challenges I solved in the CTF. I mainly focused on Rev and Pwn categories.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-15_watevr-ctf-2019-writeups/"}},{id:"post-tuctf-2019-pwn-amp-rev-challenges",title:"TUCTF 2019 - Pwn &amp; Rev Challenges",description:"My writeups for some of the PWN challenges of TUCTF 2019.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-02_tuctf-pwn-2019/"}},{id:"post-ritsec-ctf-2019",title:"RITSEC CTF 2019",description:"My writeups for RITSEC CTF 2019. A bit late, but I hope this helps someone!",section:"Posts",handler:()=>{window.location.href="/post/2019-11-19_ritsec-ctf-2019/"}},{id:"post-codefest-39-19-ctf-writeups",title:"Codefest&#39;19 CTF Writeups",description:"The Capture the Flag event for Codefest&#39;19 was hosted from 8 pm IST, 23rd August 2019 to 12 noon IST, 24th August 2019 on Hackerrank.",section:"Posts",handler:()=>{window.location.href="/post/2019-08-25_codefest19-ctf-writeups/"}},{id:"post-angstromctf-writeups",title:"AngstromCTF Writeups",description:"These are the writeups to the problems I solved during the AngstromCTF.",section:"Posts",handler:()=>{window.location.href="/post/2018-03-23_angstromctf-writeups/"}},{id:"post-neverlan-ctf-2018-writeups",title:"NeverLAN CTF 2018 Writeups",description:"These are the writeups of the problems I solved over the weekend for the NeverLAN CTF 2018.",section:"Posts",handler:()=>{window.location.href="/post/2018-02-27_neverlan-ctf-2018-writeups/"}},{id:"news-paper-accepted-at-the-workshop-on-multilingual-surface-realisation-acl",title:"Paper accepted at the Workshop on Multilingual Surface Realisation, ACL",description:"",section:"News",handler:()=>{window.location.href="/news/srst-acl/"}},{id:"news-won-a-student-scholarship-to-attend-blackhat-asia-2019-singapore-100-students-were-selected-from-82-countries",title:"Won a student scholarship to attend BlackHat Asia 2019, Singapore. 100 students were...",description:"",section:"News"},{id:"news-started-to-work-as-a-ta-for-the-artificial-intelligence-course-offered-to-sophomores-of-the-cse-department-of-iit-bhu-varanasi",title:"Started to work as a TA for the Artificial Intelligence course offered to...",description:"",section:"News"},{id:"news-got-my-first-job-and-started-my-career-in-the-field-of-ai-as-a-research-data-scientist-at-mastercard-ai-garage",title:"Got my first job and started my career in the field of AI...",description:"",section:"News"},{id:"news-silver-medal-shopee-price-match-guarantee-competition",title:"Silver medal - Shopee - Price Match Guarantee Competition",description:"",section:"News",handler:()=>{window.location.href="/news/silver-kaggle/"}},{id:"news-paper-accepted-at-the-30th-international-conference-on-artificial-neural-networks-icann-2021",title:"Paper accepted at the 30th International Conference on Artificial Neural Networks (ICANN 2021)...",description:"",section:"News",handler:()=>{window.location.href="/news/icann/"}},{id:"news-paper-accepted-at-the-28th-international-conference-on-neural-information-processing-iconip-2021",title:"Paper accepted at the 28th International Conference on Neural Information Processing (ICONIP 2021)...",description:"",section:"News",handler:()=>{window.location.href="/news/iconip/"}},{id:"news-joined-level-ai-as-a-machine-learning-engineer-in-nlp",title:"Joined Level AI as a Machine Learning Engineer in NLP.",description:"",section:"News"},{id:"news-promoted-to-senior-ml-engineer-at-level-ai",title:"Promoted to Senior ML Engineer at Level AI!",description:"",section:"News"},{id:"news-promoted-to-lead-ml-engineer-at-level-ai",title:"Promoted to Lead ML Engineer at Level AI!",description:"",section:"News"},{id:"news-promoted-to-principal-ml-engineer-at-level-ai",title:"Promoted to Principal ML Engineer at Level AI!",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%72%65%79%61%6E%73%68.%70%65%74%74%73%77%6F%6F%64@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=x8LmoJIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/shreyansh26","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shreyansh26","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/shreyansh_26","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@shreyansh26","_blank")}},{id:"socials-instagram",title:"Instagram",section:"Socials",handler:()=>{window.open("https://instagram.com/shreyanshs","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>