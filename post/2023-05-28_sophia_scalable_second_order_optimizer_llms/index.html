<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Summary #9 - Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training | Shreyansh Singh </title> <meta name="author" content="Shreyansh Singh"> <meta name="description" content="Understanding Sophia - A new fast, scalable second-order optimizer which beats Adam on LLM pretraining."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link defer href="/assets/css/toc-custom.css?756dbf96bc5f3a1ff6fe40e2951f47f7" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile_pictures/favicon.ico?7def459033b808c2a47593bed4cfb002"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shreyansh26.github.io/post/2023-05-28_sophia_scalable_second_order_optimizer_llms/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shreyansh</span> Singh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/post/index.html">Posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/bookshelf/">Bookshelf </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resume/Resume_Shreyansh.pdf">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Summary #9 - Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training</h1> <p class="post-meta"> Published on May 28, 2023 by Shreyansh Singh </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   <a href="/blog/tag/optimizer"> <i class="fa-solid fa-hashtag fa-sm"></i> optimizer</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/paper-summaries"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-summaries</a>   ·   <a href="/blog/category/deep-learning"> <i class="fa-solid fa-tag fa-sm"></i> Deep Learning</a>   <a href="/blog/category/ml-theory"> <i class="fa-solid fa-tag fa-sm"></i> ML Theory</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/featured.png" alt=""> <figcaption></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p><strong>Paper</strong>: Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training<br> <strong>Link</strong>: <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a><br> <strong>Authors</strong>: Hong Liu, Zhiyuan Li, David Hall, Percy Liang, Tengyu Ma<br> <strong>Code</strong>: <a href="https://github.com/Liuhong99/Sophia" rel="external nofollow noopener" target="_blank">https://github.com/Liuhong99/Sophia</a></p> <hr> <p><strong>I have also released an annotated version of the paper. You can find it <a href="https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Sophia%20-%20A%20Scalable%20Stochastic%20Second-order%20Optimizer%20for%20Language%20Model%20Pretraining.pdf" rel="external nofollow noopener" target="_blank">here</a>.</strong></p> <p>Sophia is probably one of the most interesting papers I have read recently and I really liked how well it was written. This post is basically the notes that I had made while reading the paper, which is why it is not exactly a blog post and most of it is verbatim copied from the paper. But since there are a lot of optimization-theory related concepts which have been mentioned in the paper, I have tried to add my own set of references which I have read in the past that helped me understand the paper better. Hopefully it helps someone!</p> <h1 id="overview">Overview</h1> <ul> <li>The goal of this work is to propose a new optimizer for pre-training LLMs that can improve pre-training efficiency with a faster optimizer, which either reduces the time and cost to achieve the same pre-training loss, or alternatively achieves better pre-training loss with the same budget.</li> <li>Adam and its variants have become the somewhat default optimizers which are used in LLM pretraining.</li> <li>Designing fast optimizers for LLMs is challenging because - <ul> <li>The benefit of the first-order pre-conditioner (the \(1/\sqrt{v_t}\) factor) in Adam is still not well understood.</li> <li>The choice of pre-conditioners is constrained because we can only afford light-weight options whose overhead can be offset by the speed-up in the number of iterations.</li> <li>Among the recent works on light-weight gradient-based pre-conditioners, <a href="https://arxiv.org/abs/2302.06675" rel="external nofollow noopener" target="_blank">Lion</a> stood out as it is substantially faster than Adam on vision Transformers and diffusion models but only achieves limited speed-up on LLMs.</li> </ul> </li> <li>This paper introduces Sophia, <strong>S</strong>econd-<strong>o</strong>rder Cli<strong>p</strong>ped Stoc<strong>h</strong>ast<strong>i</strong>c Optimiz<strong>a</strong>tion, a light-weight second-order optimizer that uses an inexpensive stochastic estimate of the diagonal of the Hessian as a pre-conditioner and a clipping mechanism to control the worst-case update size.</li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig1.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>Key Results - <ul> <li>Sophia achieves the same validation pre-training loss with 50% fewer number of steps than Adam.</li> <li>Sophia maintains almost the memory and average time per step and therefore the speedup also translates to 50% less total compute and 50% less wall-clock time.</li> <li>The scaling law based on model size from 125M to 770M is in favor of Sophia over Adam - the gap between Sophia and Adam with 100K steps increases as the model size increases. Sophia on a 540M-parameter model with 100K steps gives the same validation loss as Adam on a 770M-parameter model with 100K steps.<br> <br> </li> </ul> </li> <li>Checking the performance and scalability of this optimizer for pre-training much larger model sizes would (although expensive) be interesting to see.</li> <li>Sophia estimates the diagonal entries of the Hessian of the loss using a mini-batch of examples every \(k\) steps (\(k=10\) in the paper).</li> <li>The paper considers two options for diagonal Hessian estimators - <ul> <li>Hutchinson’s unbiased estimator - an unbiased estimator that uses a Hessian-vector product with the same run-time as a mini-batch gradient up to a constant factor</li> <li>Gauss-Newton-Bartlett (GNB) estimator - a biased estimator that uses one mini-batch gradient calculated with resampled labels. <br><br> </li> </ul> </li> <li>Both the estimators introduce only a 5% overhead per step (on average).</li> <li>Sophia updates the parameter with an exponential moving average (EMA) of the gradient divided by the EMA of the diagonal Hessian estimate, subsequently clipped by a scalar.</li> <li>Due to the Hessian-based pre-conditioner, Sophia adapts more efficiently, than Adam does, to the heterogeneous curvatures in different parameter dimensions, which can often occur in the landscape of LLMs losses and cause instability or slowdown.</li> <li>In terms of the loss landscape, Sophia has a more aggressive pre-conditioner than Adam - Sophia applies a stronger penalization to updates in sharp dimensions (where the Hessian is large) than the flat dimensions (where the Hessian is small), <b>ensuring a uniform <i><ins>loss decrease</ins></i> across all parameter dimensions</b>. In contrast, <strong>Adam’s updates are mostly uniform across all parameter dimensions, leading to a slower loss decrease in flat dimensions</strong>.</li> <li>Sophia’s clipping mechanism controls the worst-case size of the updates in all directions, safeguarding against the negative impact of inaccurate Hessian estimates, rapid Hessian changes over time, and non-convex landscape.</li> </ul> <h1 id="motivations">Motivations</h1> <h2 id="heterogeneous-curvatures">Heterogeneous Curvatures</h2> <ul> <li>Loss functions in modern deep learning problems often have different curvatures across different parameter dimensions.</li> <li>The paper demonstrates the limitations of Adam and Gradient Descent by considering a two dimensional loss function - \(L(\theta_{[1]},\theta_{[2]}) = L_1(\theta_{[1]}) + L_2(\theta_{[2]})\), where</li> </ul> \[\\ \begin{align} L_{1}(\theta_{[1]}) = 8(\theta_{[1]} - 1)^2(1.3\theta_{[1]}^2 + 2\theta_{[1]} + 1) \end{align} \\\] \[\\ \begin{align} L_2(\theta_{[2]}) = 1/2 (\theta_{[2]} - 4)^2 \end{align} \\\] <ul> <li>Here \(L_1\) is much sharper than \(L_2\).</li> <li>Another optimizer, SignGD is also compared which is quite old but can be understood as a simplified version of Adam, which does not involve taking the EMA for gradients and second moments of the gradients. The update then simplifies to -</li> </ul> \[\eta \cdot \nabla L(\theta)/|\nabla L(\theta)| = \eta\cdot \textup{sign}(\nabla L(\theta))\] <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig2.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>## Limitations of GD and SignGD (Adam)</p> <ul> <li>The optimal learning rate of Gradient Descent should be proportional to the inverse of the curvature, i.e., the Hessian/second derivative at the local minimum. A good set of resources to understand this in detail are some notes from University of Toronto <a href="https://www.cs.toronto.edu/~rgrosse/courses/csc2541_2022/readings/L01_intro.pdf" rel="external nofollow noopener" target="_blank">Section 2.2</a> and <a href="https://www.cs.toronto.edu/~rgrosse/courses/csc2541_2022/readings/L02_Taylor_approximations.pdf" rel="external nofollow noopener" target="_blank">Section 4.1</a>.</li> <li>So, if the curvatures of \(L_1\) and \(L_2\) at the local minima are \(h_1\) and \(h_2\) respectively (and thus \(h_1 &gt; h_2\) ). So the largest shared learning rate can only be \(1/h_1\). Hence, the convergence in \(\theta_{[2]}\) dimension is slow as also shown in the figure above. <br> <br> </li> <li>The update size of SignGD is the learning rate \(\eta\) in all dimensions. Hence, intuitively, the same update size translates to less progress in decreasing the loss in the flat direction than in the sharp direction. In the yellow curve in the above figure, the progress of SignGD in the flat dimension \(\theta_{[2]}\) is slow and along \(\theta_{[1]}\), the iterate quickly travels to the valley in the first three steps and then starts to bounce. To fully converge in the sharp dimension, the learning rate \(\eta\) needs to decay to \(0\), which will exacerbate the slow convergence in the flat dimension \(θ_{[2]}\). The trajectory of Adam is similar to SignGD and shown by the red curve in the figure. <br><br> </li> <li>The behavior of SignGD and Adam above indicates that a more aggressive pre-conditioning is needed - sharp dimensions should have relatively smaller updates than flat dimensions so that the decrease of loss is equalized in all dimensions.</li> <li>Prior work on second order optimization suggest that the optimal pre-conditioner is the Hessian which captures the curvature on each dimension.</li> <li>The Newton’s method, does something similar - the update is the gradient divided by the Hessian in each dimension.</li> </ul> \[\theta_{[1]} \leftarrow \theta_{[1]} - \eta \cdot L'_1(\theta_{[1]}) / h_1\ \ \textup{and}\ \ \theta_{[2]} \leftarrow \theta_{[2]} - \eta \cdot L'_2(\theta_{[2]})/ h_2\] <p><br></p> <h2 id="limitations-of-newtons-method">Limitations of Newton’s method</h2> <ul> <li>Vanilla Newton’s method could converge to a global maximum when the local curvature is negative.</li> <li>As shown in the blue curve in the figure, Newton’s method quickly converges to a saddle point instead of a local minimum.</li> <li>Since the curvature may change rapidly along a trajectory, the second order information can often become unreliable. <br><br> </li> <li>Sophia addresses this by considering only pre-conditioners that capture positive curvature, and introduce a per-coordinate clipping mechanism to mitigate the rapid change of Hessian. Applying those changes results in the following update -</li> </ul> \[\theta_{[1]} \leftarrow \theta_{[1]} - \eta \cdot \textup{clip}(\frac{ L'_1(\theta_{[1]})}{\max\{h_1,\epsilon\}} ,\rho)\ \textup{and}\ \theta_{[2]} \leftarrow \theta_{[2]} - \eta \cdot \textup{clip}(\frac{ L'_2(\theta_{[2]})}{\max\{h_2,\epsilon\}},\rho)\] <ul> <li>Here, \(\rho\) is a constant to control the worst-case update size, \(\epsilon\) is a very small constant (e.g., 1e-12) to avoid dividing by 0.</li> <li>The beauty here is that when the curvature of some dimension is rapidly changing or negative and thus the second-order information is misleading and possibly leads to a huge update before clipping, the clipping mechanism kicks in and the optimizer defaults to SignGD (even though this is sub-optimal for benign situations).</li> <li>The black curve in the figure starts off similarly to SignGD due to the clipping mechanism in the non-convex region, making descent opposed to converging to a local maximum. In the convex valley, it converges to the global minimum with a few steps.</li> <li>Compared with SignGD and Adam, it makes much faster progress in the flat dimension \(\theta_{[2]}\) (because the update is bigger in dimension \(\theta_{[2]}\)), while avoiding bouncing in the sharp dimension \(\theta_{[1]}\) (because the update is significantly shrunk in the sharp dimension \(\theta_{[1]}\)).</li> </ul> <h1 id="sophia-second-order-clipped-stochastic-optimization">Sophia: <strong>S</strong>econd-<strong>o</strong>rder Cli<strong>p</strong>ped Stoc<strong>h</strong>ast<strong>i</strong>c Optimiz<strong>a</strong>tion</h1> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/sophia.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <p>## EMA of diagonal Hessian estimates</p> <ul> <li>The diagonal Hessian estimates definitely have overheads, so it is computed at every \(k\) steps.</li> <li>At every time step \(t\), where \(t \ \textup{mod} \ k = 1\), the estimator returns an estimate \(h_t\) of the diagonal of the Hessian of the mini-batch loss.</li> <li>Similar to the gradient of the mini-batch loss function, the estimated diagonal Hessian can also have large noise.</li> <li>The EMA performed at every \(k\) steps helps denoise the estimates.</li> </ul> \[h_t = \beta_2 h_{t-k} + (1 - \beta_2) \hat{h}_{t} \ \textup{ if } t \ \mathrm{mod} \ k = 1 ; \textup{ else } h_t = h_{t-1}\] <h2 id="per-coordinate-clipping">Per-coordinate clipping</h2> <ul> <li>I personally found this very innovative.</li> <li>As mentioned in the previous section, the inaccuracy of Hessian estimates and the change of Hessian along the trajectory can make the second-order information unreliable.</li> <li> \[\theta_{t+1} \leftarrow \theta_{t} - \eta_t \cdot \textup{clip}(m_t / \max\{h_t,\epsilon\}, \rho)\] </li> <li>When any entry of \(h_t\) is negative, e.g., \(h_t[i] &lt; 0\), the corresponding entry in the pre-conditioned gradient \(m_t[i]/\max\{h_t[i],\epsilon\} = m_t[i]/\epsilon\) is extremely large and has the same sign as \(m_t[i]\), and thus \(\eta\cdot \textup{clip}(m_t[i] / \max\{h_t[i],\epsilon\}, \rho) = \eta\rho\cdot \textup{sign}(m_t[i])\), which is the same as stochastic momentum SignSGD.</li> <li>Sophia uses stochastic momentum SignSGD as a backup when the Hessian is negative (or mistakenly estimated to be negative or very small.)</li> <li>The clipping mechanism controls the worst-case size of the updates in all parameter dimensions to be at most \(\rho\), which also improves the stability (which could be a severe issue for second-order methods).</li> </ul> <h2 id="diagonal-hessian-estimators">Diagonal Hessian Estimators</h2> <ul> <li>I’ll keep this section short and brief, for the simple reason that the math is extremely interesting but also a bit difficult to understand. So, I’ll add references to the best of my knowledge and I encourage the reader to go through them thoroughly.</li> </ul> <h3 id="hutchinsons-unbiased-estimator">Hutchinson’s unbiased estimator</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/hutchinson.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>For any loss function \(\ell(\theta)\) on parameters \(\theta\in \mathbb{R}^d\), the Hutchinson’s estimator can be used to obtain an unbiased estimator for the diagonal of the Hessian.</li> <li>First, draw \(u\in \mathbb{R}^d\) from the spherical Gaussian distribution \(\mathcal{N}(0,\mathrm{I}_d)\), and then output \(\hat{h} = u \odot (\nabla^2 \ell(\theta) u)\), where \(\odot\) denotes the element-wise product, and \(\nabla^2 \ell(\theta) u\) is the HVP of the Hessian with \(u\).</li> <li>Using HVP (from <a href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#hessian-vector-products-using-both-forward-and-reverse-mode" rel="external nofollow noopener" target="_blank">JAX</a> or <a href="https://pytorch.org/docs/stable/generated/torch.autograd.functional.hvp.html" rel="external nofollow noopener" target="_blank">Pytorch</a> allows us to efficiently compute the product of the Hessian and a vector without the actual computation of the full Hessian matrix.</li> <li>Effectively, \(\mathbb{E}[\hat h] = \mathrm{diag}(\nabla^2 \ell(\theta))\). <br><br> </li> <li> <strong>How does it work?</strong> The idea for the above comes from the original paper from Hutchinson - “A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines” which was about estimating the trace of a matrix. The idea there was -</li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig3.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>Dimensionally, and somewhat intuitively, it kinda makes sense to change the dot product to an elementwise product to get the non-aggregated estimate of the diagonal (since trace is the sum of the diagonal elements).</li> <li>This idea was also used in the <a href="https://arxiv.org/abs/2006.00719" rel="external nofollow noopener" target="_blank">“Hessian Diagonal Approximation” section of the AdaHessian paper</a>, and I would also encourage the reader to go through <a href="https://www-users.cse.umn.edu/~saad/PDF/umsi-2005-082.pdf" rel="external nofollow noopener" target="_blank">Section 2 of the paper - “An Estimator for the Diagonal of a Matrix”</a>, which the AdaHessian paper cites as well.</li> </ul> <h3 id="gauss-newton-bartlett-gnb-estimator">Gauss-Newton-Bartlett (GNB) estimator</h3> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/gnb.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>The math for this section is particularly interesting and I would redirect you to my <a href="https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Sophia%20-%20A%20Scalable%20Stochastic%20Second-order%20Optimizer%20for%20Language%20Model%20Pretraining.pdf" rel="external nofollow noopener" target="_blank">annotated paper</a> where I have mentioned references and also worked out some of the math.</li> <li>I’d highly recommend reading <a href="https://www.cs.toronto.edu/~rgrosse/courses/csc2541_2022/readings/L02_Taylor_approximations.pdf" rel="external nofollow noopener" target="_blank">Section 4.4 of these notes</a> and optionally <a href="https://www.cs.toronto.edu/~rgrosse/courses/csc2541_2022/readings/L03_metrics.pdf" rel="external nofollow noopener" target="_blank">Section 4 of these notes</a> (not absolutely required, just helps to understand the footnote in the Sophia paper).</li> <li>Ultimately, the GNB estimator used by the authors is \(B \cdot \nabla_\theta \widehat L(\theta) \odot \nabla_\theta \widehat L(\theta)\) where</li> </ul> \[\\ \begin{align} \widehat L(\theta) = \frac{1}{B}\sum_{b=1}^B \ce(f(\theta, x_b), \hat{y}_b) \end{align} \\\] <p>here \(\hat{y}_b\) are not the labels corresponding to \(x_b\). They are just <strong>sampled labels</strong> from the mini-batch.</p> <ul> <li>The reason we can do that is in the math, which comes from the combination of <ol> <li>The claim in the paper that the second-order derivative of the loss w.r.t. the logits only depends on the logits and the true labels \(y\).</li> <li>Bartlett’s first identity, which generally holds for the negative log-likelihood loss of any probabilistic model and which states - \(\forall b, \mathbb{E}_{\hat{y}_b}\nabla L_\textup{ce}(f(\theta,x_b),\hat{y}_b) = 0\)</li> </ol> </li> <li>Also, the above estimator is an unbiased estimator for the diagonal of the Gauss-Newton matrix, which is a biased estimator for the diagonal of the Hessian.</li> <li>Additional References - <a href="https://www.sfu.ca/~lockhart/richard/830/12_3/Summaries/8.pdf" rel="external nofollow noopener" target="_blank">Bartlett Identities</a> </li> </ul> <h3 id="comparison-of-hessian-estimators">Comparison of Hessian estimators</h3> <ul> <li>The Hutchinson’s estimator does not assume any structure of the loss, but requires a Hessian-vector product.</li> <li>The GNB estimator only estimates the Gauss-Newton term but always gives a positive semi-definite (non-negative) diagonal Hessian estimate. The PSDness ensures that the pre-conditioned update is always a descent direction.</li> <li>The Gauss-Newton Matrix is guaranteed to be PSD if the above-mentioned second-order derivative of the loss w.r.t. the logits is PSD. For proof, <a href="https://andrew.gibiansky.com/blog/machine-learning/gauss-newton-matrix/" rel="external nofollow noopener" target="_blank">refer this</a>.</li> </ul> <h1 id="experiments">Experiments</h1> <ul> <li>There are tons of details in the paper regarding the experiments. I’ll just mention the key points here.</li> </ul> <h2 id="experimental-setup">Experimental Setup</h2> <h3 id="baselines">Baselines</h3> <ul> <li>Main comparison with AdamW and Lion</li> <li>AdamW for GPT2 hyperparams - WD = 0.1, \(\beta_1 = 0.9\) and \(\beta_2 = 0.95\)</li> <li>Lion for GPT2 hyperparams - \(\beta_1 = 0.95\) and \(\beta_2 = 0.98\)</li> </ul> <h3 id="implementation">Implementation</h3> <ul> <li>Batch Size = 480</li> <li>Cosine LR schedule with the final LR equal to 0.05 times the peak LR</li> <li>Standard gradient clipping (by norm) threshold 1.0</li> <li>Fixed 2k steps of LR warm-up</li> <li>For Sophia, the authors use \(\beta_1 = 0.96\), \(\beta_2 = 0.99\), \(\epsilon=\) 1e-12 and update diagonal Hessian every 10 steps.</li> <li>Sophia-H (which refers to Sophia with Hutchinson estimator) uses \(\rho=0.01\), and only a subset of 32 examples from the mini-batch to calculate the diagonal Hessian to further reduce overhead.</li> <li>Sophia-G (which refers to Sophia with GNB estimator) uses \(\rho=20\), and use a subset of 240 examples from the mini-batch to calculate the diagonal Gauss-Newton.</li> <li>All models are trained in bfloat16.</li> <li>The 125M and 355M models are trained on A5000 GPUs, while the 770M models are trained on A100 GPUs. Total amount of compute spent on all experiments is about 6000 hours on A100s and 10000 hours on A5000s. This amounts to 4.38e21 FLOPs.</li> </ul> <h1 id="results">Results</h1> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig4.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>Sophia consistently achieves better validation loss than AdamW and Lion.</li> <li>As the model size grows, the gap between Sophia and baselines also becomes larger. Sophia-H and Sophia-G both achieve a 0.04 smaller validation loss on the 355M model, Sophia-H achieves a 0.05 smaller validation loss on the 770M model with the same 100k steps.</li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig5.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>According to the scaling laws in this regime, an improvement in loss of 0.05 is equivalent to 2x improvement in terms of number of steps or total compute to achieve the same validation loss</li> <li>Sophia is 2x faster in terms of number of steps, total compute and wall-clock time.</li> <li> <strong>The scaling law is in favor of Sophia-H over AdamW</strong> <ul> <li>The 540M model trained by Sophia-H has smaller loss than the 770M model trained by AdamW.</li> <li>The 355M model trained by Sophia-H has comparable loss as the 540M model trained by AdamW.</li> </ul> </li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig6.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li> <strong>Few-shot Evaluation on Downstream Tasks (SuperGLUE)</strong> <ul> <li>GPT-2 medium and GPT-2 large pre-trained with Sophia have better few-shot accuracy on most subtasks.</li> <li>Models pre-trained with Sophia-H have comparable few-shot accuracy as models pre-trained with AdamW for 2x number of steps.</li> </ul> </li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig7.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li> <strong>Sensitivity to \(\rho\) and \(\beta_2\), and transferability of hyperparameters</strong> <ul> <li>While performing grid search on hyperparams on a smaller 30M model, the authors found that all combinations have a similar performance. Moreover, this hyperparameter choice is transferable across model sizes. For all the experiments on 125M, 355M and 770M, we use the hyperparameters searched on the 30M model, which is ρ = 0.01, β2 = 0.99.</li> </ul> </li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig8.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li> <strong>Training Stability</strong> <ul> <li>Gradient clipping (by norm) is an important technique in language model pre-training as it avoids messing up the moment of gradients with one mini-batch gradient computed from rare data.</li> <li>In practice, the frequency that gradients clipping is triggered is related to the training stability - if the gradient is frequently clipped, the iterate can be in a very unstable state.</li> <li>Although all methods use the same clipping threshold 1.0, Sophia-H seldomly triggers gradient clipping, while AdamW and Lion trigger gradient clipping in more than 10% of the steps</li> </ul> </li> </ul> <div class="outer"> <figure class="image"> <img src="/assets/img/posts_images/sophia_optimizer/fig9.png" alt="Source - &lt;a href='https://arxiv.org/abs/2305.14342'&gt;https://arxiv.org/abs/2305.14342&lt;/a&gt;"> <figcaption>Source - <a href="https://arxiv.org/abs/2305.14342" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2305.14342</a></figcaption> <br> </figure> </div> <style>.outer{display:block;text-align:center;max-width:100%}.image{display:inline-block;max-width:100%;margin:0 auto}.image img{max-width:100%;width:auto;height:auto}figure.embed,figure.embed-top,figure.overlay,figure.embed-over{display:inline-block;text-align:initial;vertical-align:top;position:relative;margin:.5em;font-size:.8em;background:white;overflow:hidden}figure.embed img,figure.embed-top img,figure.overlay img,figure.embed-over img{display:block;margin-left:auto;margin-right:auto}` figure.embed figcaption,figure.embed-top figcaption,figure.overlay figcaption,figure.embed-over figcaption{` width:100%;padding:.5em;color:rgba(50,50,50,1);background:rgba(200,200,200,0.825)}figcaption{display:block;font-size:80%}</style> <ul> <li>Another common trick of pre-training deep Transformers is scaling the product of keys and values by the inverse of the layer index [<a href="https://crfm.stanford.edu/2021/08/26/mistral.html" rel="external nofollow noopener" target="_blank">Mistral</a>]. This stabilizes training and increases the largest possible learning rate. <ul> <li>Without this trick, the maximum learning rate of AdamW and Lion on GPT-2 medium (355M) can only be 1.5e-4, which is much smaller than 3e-4 with the trick (the loss will blow up with 3e-4 without the trick). Moreover, the loss decreases much slower without the trick as shown. In all the experiments, Sophia-H does not require scaling the product of keys and values by the inverse of the layer index.</li> </ul> </li> </ul> <h1 id="limitations">Limitations</h1> <ul> <li>Scaling up to larger models and datasets <ul> <li>The paper only experiments with GPT-2 pretraining on OpenWebText for model sizes up to 770M params.</li> <li>Although it is faster and better than Adam and Lion in these set of experiments, and the scaling laws and pre-training stability are encouraging, it remains to be seen how well Sophia scales on larger models.</li> </ul> </li> <li>Holistic downstream evaluation <ul> <li>The paper has only experimented with 4 SuperGLUE tasks and although the results are encouraging, a better downstream evaluation is still important.</li> <li>To note - The limitation in downstream evaluation is also due to the limited model size, because language models at this scale do not have enough capabilities such as in-context learning, and mathematical reasoning.</li> </ul> </li> <li>Evaluation on other domains <ul> <li>This paper focuses on optimizers for LLMs, it should be evaluated in other domains like CV, RL and Multimodal tasks.</li> </ul> </li> </ul> <hr> <p>A very exciting paper. Hope people can test it out on even bigger models and across multiple domains and we may potentially have an optimizer finally dethroning Adam!</p> <p> </p> <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script> <div class="button_cont" align="center"><button id="openpopup" class="example_a">Subscribe to my posts!</button></div> <style>.example_a{color:#fff!important;text-transform:uppercase;text-decoration:none;background:#3f51b5;padding:20px;border-radius:5px;cursor:pointer;display:inline-block;border:0;transition:all .4s ease 0}.example_a:hover{background:#434343;letter-spacing:1px;-webkit-box-shadow:0 5px 40px -10px rgba(0,0,0,0.57);-moz-box-shadow:0 5px 40px -10px rgba(0,0,0,0.57);box-shadow:5px 40px -10px rgba(0,0,0,0.57);transition:all .4s ease 0}</style> <script type="text/javascript">function showMailingPopUp(){window.dojoRequire(["mojo/signup-forms/Loader"],function(o){o.start({baseUrl:"mc.us4.list-manage.com",uuid:"0b10ac14f50d7f4e7d11cf26a",lid:"667a1bb3da",uniqueMethods:!0})}),document.cookie="MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC"}document.getElementById("openpopup").onclick=function(){showMailingPopUp()};</script> <p> </p> <script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js" data-id="shreyanshsingh" data-description="Support me on Buy me a coffee!" data-message="" data-color="#FF5F5F" data-position="Right" data-x_margin="18" data-y_margin="18"></script> <p>Follow me on <a href="https://twitter.com/shreyansh_26" rel="external nofollow noopener" target="_blank">Twitter</a>, <a href="https://github.com/shreyansh26" rel="external nofollow noopener" target="_blank">Github</a> or connect on <a href="https://www.linkedin.com/in/shreyansh26/" rel="external nofollow noopener" target="_blank">LinkedIn</a>.</p> </div> </article> <div id="giscus_thread" style="max-width: 1200px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"shreyansh26/shreyansh26.github.io","data-repo-id":"R_kgDOMn767Q","data-category":"General","data-category-id":"DIC_kwDOMn767c4CiLUv","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Shreyansh Singh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?317646887210841a1b23a5eedc9fba39"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZEZ7673Y7G"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-ZEZ7673Y7G");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-posts",title:"Posts",description:"",section:"Navigation",handler:()=>{window.location.href="/post/index.html"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-bookshelf",title:"Bookshelf",description:"A list of books I&#39;ve read and some of which I&#39;ve found interesting :)",section:"Navigation",handler:()=>{window.location.href="/bookshelf/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/resume/Resume_Shreyansh.pdf"}},{id:"post-faster-cross-encoder-inference-unleashing-torch-compile-for-speed",title:"Faster Cross-Encoder Inference: Unleashing torch.compile for speed",description:"A quick writeup on accelerating a Jina Cross-Encoder using torch.compile",section:"Posts",handler:()=>{window.location.href="/post/2025-03-02_cross-encoder-inference-torch-compile/"}},{id:"post-paper-summary-13-physics-of-language-models-part-2-1-grade-school-math-and-the-hidden-reasoning-process",title:"Paper Summary #13 - Physics of Language Models: Part 2.1, Grade-School Math and...",description:"My notes from the Physics of Language Models series of papers.",section:"Posts",handler:()=>{window.location.href="/post/2024-09-21_physics-of-lms-2-1-grade-school-math-and-the-hidden-reasoning-process/"}},{id:"post-paper-summary-12-image-recaptioning-in-dall-e-3",title:"Paper Summary #12 - Image Recaptioning in DALL-E 3",description:"The image recaptioning technique used in DALL-E 3 was extended to videos in Sora.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_dalle3_image_recaptioner/"}},{id:"post-paper-summary-11-sora",title:"Paper Summary #11 - Sora",description:"OpenAI announced a ground-breaking text-to-video diffusion model capable of generating high-definition videos up to 60 seconds long.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_sora_openai/"}},{id:"post-paper-summary-10-gemini-1-5-pro",title:"Paper Summary #10 - Gemini 1.5 Pro",description:"Google DeepMind announced a multimodal LLM with support of up to 10M context length.",section:"Posts",handler:()=>{window.location.href="/post/2024-02-18_gemini_pro_google/"}},{id:"post-solving-substitution-ciphers-using-markov-chain-monte-carlo-mcmc",title:"Solving Substitution Ciphers using Markov Chain Monte Carlo (MCMC)",description:"Deciphering substitution ciphers can be framed as a Markov chain problem and a simple Monte Carlo sampling approach can help solve them very efficiently",section:"Posts",handler:()=>{window.location.href="/post/2023-07-22_solving_substitution_cipher_using_mcmc/"}},{id:"post-paper-summary-9-sophia-a-scalable-stochastic-second-order-optimizer-for-language-model-pre-training",title:"Paper Summary #9 - Sophia: A Scalable Stochastic Second-order Optimizer for Language Model...",description:"Understanding Sophia - A new fast, scalable second-order optimizer which beats Adam on LLM pretraining.",section:"Posts",handler:()=>{window.location.href="/post/2023-05-28_sophia_scalable_second_order_optimizer_llms/"}},{id:"post-paper-summary-8-flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness",title:"Paper Summary #8 - FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",description:"Understanding FlashAttention which is the most efficient exact attention implementation out there, which optimizes for both memory requirements and wall-clock time.",section:"Posts",handler:()=>{window.location.href="/post/2023-03-26_flash-attention/"}},{id:"post-paper-summary-7-efficient-transformers-a-survey",title:"Paper Summary #7 - Efficient Transformers: A Survey",description:"A survey paper of improvements over the original Transformer architecture in terms of memory-efficiency.",section:"Posts",handler:()=>{window.location.href="/post/2022-10-10_efficient_transformers_survey/"}},{id:"post-deploying-machine-learning-models-using-gcp-39-s-google-ai-platform-a-detailed-tutorial",title:"Deploying Machine Learning models using GCP&#39;s Google AI Platform - A Detailed Tutorial...",description:"A step-wise tutorial to demonstrate the steps required to deploy a ML model using GCP, specifically the Google AI Platform and use Streamlit to access the model through a UI.",section:"Posts",handler:()=>{window.location.href="/post/2022-03-06_model_deployment_using_gcp_google_ai_platform/"}},{id:"post-deploying-machine-learning-models-using-aws-lambda-and-github-actions-a-detailed-tutorial",title:"Deploying Machine Learning models using AWS Lambda and Github Actions - A Detailed...",description:"A step-wise tutorial to demonstrate the steps required to deploy a ML model using AWS Lambda, Github Actions, API Gateway and use Streamlit to access the model API through a UI.",section:"Posts",handler:()=>{window.location.href="/post/2022-01-23_model_deployment_using_aws_lambda/"}},{id:"post-ppml-series-3-federated-learning-for-mobile-keyboard-prediction",title:"PPML Series #3 - Federated Learning for Mobile Keyboard Prediction",description:"Understanding how your mobile keyboard (Gboard, specifically) performs the next word prediction task and performs model training and updates",section:"Posts",handler:()=>{window.location.href="/post/2021-12-27_federated_learning_mobile_keyboard/"}},{id:"post-ppml-series-2-federated-optimization-algorithms-fedsgd-and-fedavg",title:"PPML Series #2 - Federated Optimization Algorithms - FedSGD and FedAvg",description:"A mathematical deep dive on a Federated Optimization algorithm - FedAvg and comparing it with a standard approach - FedSGD.",section:"Posts",handler:()=>{window.location.href="/post/2021-12-18_federated_optimization_fedavg/"}},{id:"post-ppml-series-1-an-introduction-to-federated-learning",title:"PPML Series #1 - An introduction to Federated Learning",description:"A short general introduction to Federated Learning (FL) for folks interested in privacy-preserving machine learning (PPML).",section:"Posts",handler:()=>{window.location.href="/post/2021-12-11_intro_to_federated_learning/"}},{id:"post-paper-summary-6-language-models-are-unsupervised-multitask-learners",title:"Paper Summary #6 - Language Models are Unsupervised Multitask Learners",description:"The GPT2 model which aimed to perform complex NLP tasks while relying only on a language model trained in a completely unsupervised fashion.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/"}},{id:"post-paper-summary-5-xlnet-generalized-autoregressive-pretraining-for-language-understanding",title:"Paper Summary #5 - XLNet: Generalized Autoregressive Pretraining for Language Understanding",description:"XLNet tries to overcome the limitations of BERT by having a autoregressive component while also capturing the bidirectional context.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/"}},{id:"post-paper-summary-4-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding",title:"Paper Summary #4 - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding...",description:"The ground breaking paper that introduced the famous BERT model. This started the inflow of a large number of BERT-based language understanding models.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/"}},{id:"post-paper-summary-3-improving-language-understanding-by-generative-pre-training",title:"Paper Summary #3 - Improving Language Understanding by Generative Pre-Training",description:"The first paper in the GPT set of models. This is OpenAI&#39;s GPT-1.",section:"Posts",handler:()=>{window.location.href="/post/2021-05-02_language_understanding_generative_pretraining/"}},{id:"post-paper-summary-2-deep-contextualized-word-representations-elmo",title:"Paper Summary #2 - Deep contextualized word representations (ELMo)",description:"The second post in the paper notes series. This time we take a look at ELMo.",section:"Posts",handler:()=>{window.location.href="/post/2021-04-25_deep_contextualized_word_representations_elmo/"}},{id:"post-paper-summary-1-attention-is-all-you-need",title:"Paper Summary #1 - Attention Is All You Need",description:"The first of the paper summary series. This is where I briefly summarise the important papers that I read for my job or just for fun :P",section:"Posts",handler:()=>{window.location.href="/post/2021-04-18_attention_is_all_you_need/"}},{id:"post-deep-learning-in-the-browser-exploring-tf-js-webdnn-and-onnx-js",title:"Deep Learning in the Browser - Exploring TF.js, WebDNN and ONNX.js",description:"A quick tutorial to set up a small scale deployment for your ML or DL model",section:"Posts",handler:()=>{window.location.href="/post/2021-01-25_deep_learning_in_the_browser/"}},{id:"post-quick-tutorial-to-deploy-your-ml-models-using-fastapi-and-docker",title:"Quick tutorial to deploy your ML models using FastAPI and Docker",description:"Just a quick tutorial to set up a small scale deployment for your ML or DL model",section:"Posts",handler:()=>{window.location.href="/post/2020-11-30_fast_api_docker_ml_deploy/"}},{id:"post-androids-encryption-crypto-pwn2win-ctf-2020",title:"Androids Encryption (Crypto) - Pwn2Win CTF 2020",description:"My writeup for Androids Encryption challenge in the Pwn2Win CTF 2020",section:"Posts",handler:()=>{window.location.href="/post/2020-06-01_androids_encryption-pwn2win-2020/"}},{id:"post-malwaretech-39-s-vm1-reversing-challenge",title:"MalwareTech&#39;s VM1 Reversing Challenge",description:"My writeup for the VM1 reversing challenge posted by MalwareTech on his website.",section:"Posts",handler:()=>{window.location.href="/post/2020-01-04_malwaretech-vm1-challenge/"}},{id:"post-hxp-36c3-ctf-writeups",title:"hxp 36C3 CTF Writeups",description:"The writeups for the challenges I solved in the first MAJOR CTF that I participated in after a long time.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-30_hxp-36c3-ctf/"}},{id:"post-watevrctf-2019-writeups-mainly-rev-and-pwn",title:"watevrCTF 2019 Writeups (Mainly Rev and Pwn)",description:"My writeups for the challenges I solved in the CTF. I mainly focused on Rev and Pwn categories.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-15_watevr-ctf-2019-writeups/"}},{id:"post-tuctf-2019-pwn-amp-rev-challenges",title:"TUCTF 2019 - Pwn &amp; Rev Challenges",description:"My writeups for some of the PWN challenges of TUCTF 2019.",section:"Posts",handler:()=>{window.location.href="/post/2019-12-02_tuctf-pwn-2019/"}},{id:"post-ritsec-ctf-2019",title:"RITSEC CTF 2019",description:"My writeups for RITSEC CTF 2019. A bit late, but I hope this helps someone!",section:"Posts",handler:()=>{window.location.href="/post/2019-11-19_ritsec-ctf-2019/"}},{id:"post-codefest-39-19-ctf-writeups",title:"Codefest&#39;19 CTF Writeups",description:"The Capture the Flag event for Codefest&#39;19 was hosted from 8 pm IST, 23rd August 2019 to 12 noon IST, 24th August 2019 on Hackerrank.",section:"Posts",handler:()=>{window.location.href="/post/2019-08-25_codefest19-ctf-writeups/"}},{id:"post-angstromctf-writeups",title:"AngstromCTF Writeups",description:"These are the writeups to the problems I solved during the AngstromCTF.",section:"Posts",handler:()=>{window.location.href="/post/2018-03-23_angstromctf-writeups/"}},{id:"post-neverlan-ctf-2018-writeups",title:"NeverLAN CTF 2018 Writeups",description:"These are the writeups of the problems I solved over the weekend for the NeverLAN CTF 2018.",section:"Posts",handler:()=>{window.location.href="/post/2018-02-27_neverlan-ctf-2018-writeups/"}},{id:"news-paper-accepted-at-the-workshop-on-multilingual-surface-realisation-acl",title:"Paper accepted at the Workshop on Multilingual Surface Realisation, ACL",description:"",section:"News",handler:()=>{window.location.href="/news/srst-acl/"}},{id:"news-won-a-student-scholarship-to-attend-blackhat-asia-2019-singapore-100-students-were-selected-from-82-countries",title:"Won a student scholarship to attend BlackHat Asia 2019, Singapore. 100 students were...",description:"",section:"News"},{id:"news-started-to-work-as-a-ta-for-the-artificial-intelligence-course-offered-to-sophomores-of-the-cse-department-of-iit-bhu-varanasi",title:"Started to work as a TA for the Artificial Intelligence course offered to...",description:"",section:"News"},{id:"news-got-my-first-job-and-started-my-career-in-the-field-of-ai-as-a-research-data-scientist-at-mastercard-ai-garage",title:"Got my first job and started my career in the field of AI...",description:"",section:"News"},{id:"news-silver-medal-shopee-price-match-guarantee-competition",title:"Silver medal - Shopee - Price Match Guarantee Competition",description:"",section:"News",handler:()=>{window.location.href="/news/silver-kaggle/"}},{id:"news-paper-accepted-at-the-30th-international-conference-on-artificial-neural-networks-icann-2021",title:"Paper accepted at the 30th International Conference on Artificial Neural Networks (ICANN 2021)...",description:"",section:"News",handler:()=>{window.location.href="/news/icann/"}},{id:"news-paper-accepted-at-the-28th-international-conference-on-neural-information-processing-iconip-2021",title:"Paper accepted at the 28th International Conference on Neural Information Processing (ICONIP 2021)...",description:"",section:"News",handler:()=>{window.location.href="/news/iconip/"}},{id:"news-joined-level-ai-as-a-machine-learning-engineer-in-nlp",title:"Joined Level AI as a Machine Learning Engineer in NLP.",description:"",section:"News"},{id:"news-promoted-to-senior-ml-engineer-at-level-ai",title:"Promoted to Senior ML Engineer at Level AI!",description:"",section:"News"},{id:"news-promoted-to-lead-ml-engineer-at-level-ai",title:"Promoted to Lead ML Engineer at Level AI!",description:"",section:"News"},{id:"news-promoted-to-principal-ml-engineer-at-level-ai",title:"Promoted to Principal ML Engineer at Level AI!",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%72%65%79%61%6E%73%68.%70%65%74%74%73%77%6F%6F%64@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=x8LmoJIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/shreyansh26","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shreyansh26","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/shreyansh_26","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@shreyansh26","_blank")}},{id:"socials-instagram",title:"Instagram",section:"Socials",handler:()=>{window.open("https://instagram.com/shreyanshs","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>